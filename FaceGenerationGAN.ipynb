{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a02fab-608f-405e-92d7-6155197fe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cc85c-5bbd-4ce9-89da-7c8f9b084710",
   "metadata": {},
   "source": [
    "### Function to make a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d82d39-e745-427e-8063-bc539dc25e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(img_dir, image_size=128, batch_size=16, num_workers=0):\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                    transforms.ToTensor()])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(img_dir, transform)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=num_workers)\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea61aa1-e710-4cb1-bb9e-f80a776e73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\manou\\Downloads\\processed-celeba-small\\processed_celeba_small\"\n",
    "\n",
    "data_loader = get_data_loader(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef8f9a-5c55-41d3-a452-9d525414564b",
   "metadata": {},
   "source": [
    "### Displays images\n",
    "To make sure the data was batched correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cee940-4518-41f5-acbe-c4bff3c33aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.imshow(np.transpose(img.numpy(), (1,2,0)))\n",
    "\n",
    "dataiter = iter(data_loader)\n",
    "images, _ = dataiter.next()\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d456ed2-2a0f-4e3f-b922-c1e7e95e11fa",
   "metadata": {},
   "source": [
    "### Scales images\n",
    "In many GAN papers, they use a tanh activation function because it tends to perform the best. This means the data must be scaled  [-1, 1]  instead of  [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6b5af-5ac7-4993-8dc1-0e6ae204e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, feature_range=(-1,1)):\n",
    "    min, max = feature_range\n",
    "    x = x*(max-min)+min\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca6c24-5532-4193-ab7a-75688f20016b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Max :', images[0].max())\n",
    "print('Min :', images[0].min())\n",
    "\n",
    "print('-'*24)\n",
    "im_scaled = scale(images[0])\n",
    "\n",
    "print('Max :', im_scaled.max())\n",
    "print('Min :', im_scaled.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f07c521-27c6-4e63-9907-5e3d6f68e09b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creates the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac719de-ca8a-441c-bcab-43131c87cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, conv_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Defines the convolutional and normalization layers\n",
    "        self.conv1 = nn.Conv2d(3, conv_dim, 4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(conv_dim, conv_dim*2, 4, stride=2, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(conv_dim*2)\n",
    "        self.conv3 = nn.Conv2d(conv_dim*2, conv_dim*4, 4, stride=2, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(conv_dim*4)\n",
    "        self.fc = nn.Linear(256*16*16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = x.size(0)\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.norm1(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.norm2(self.conv3(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(x0, -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        #print(x.shape)\n",
    "        #print()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269786d-a609-4d15-9bc5-0c674161903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_size=100, conv_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        # sets variable\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        ## generator layers\n",
    "        # fc layer\n",
    "        self.linear = nn.Linear(z_size, 256*16*16)\n",
    "        \n",
    "        # every other layer\n",
    "        self.trans1 = nn.ConvTranspose2d(conv_dim*4, conv_dim*2, 4,\n",
    "                                         stride=2, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(conv_dim*2)\n",
    "        self.trans2 = nn.ConvTranspose2d(conv_dim*2, conv_dim, 4,\n",
    "                                         stride=2, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(conv_dim)\n",
    "        self.trans3 = nn.ConvTranspose2d(conv_dim, 3, 4,\n",
    "                                       stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.linear(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.conv_dim*4, 16, 16)\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.norm1(self.trans1(x)))\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.norm2(self.trans2(x)))\n",
    "        #print(x.shape)\n",
    "        x = F.tanh(self.trans3(x))\n",
    "        #print(x.shape)\n",
    "        #print()\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48174a33-9b08-46f6-abeb-53f156f1e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "G = Generator()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if train_on_gpu:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "    print('gpu babyyyyy!')\n",
    "else:\n",
    "    G.cpu()\n",
    "    D.cpu()\n",
    "    print('training on cpu')\n",
    "    \n",
    "print(D)\n",
    "print()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93734e-c24c-4c74-b6ec-73a3f4a02f4a",
   "metadata": {},
   "source": [
    "### Defines loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e620c1-eaae-4cf9-9136-43540571755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(d_out, smooth=False):\n",
    "    batch_size = d_out.size(0)\n",
    "    if smooth:\n",
    "        labels = torch.ones(batch_size)*0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size)\n",
    "    if train_on_gpu:\n",
    "        labels = labels.gpu()\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(d_out.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss(d_out):\n",
    "    batch_size = d_out.size(0)\n",
    "    labels = torch.zeros(batch_size)\n",
    "    if train_on_gpu:\n",
    "        labels = labels.gpu()\n",
    "        \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(d_out.squeeze(), labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf0de8-6542-4986-b807-80651a6a4594",
   "metadata": {},
   "source": [
    "### Defines optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c79872-af03-437f-85aa-9872a5d1ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.99\n",
    "\n",
    "d_optimizer = optim.Adam(D.parameters(), lr, [beta1, beta2])\n",
    "g_optimizer = optim.Adam(G.parameters(), lr, [beta1, beta2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7257e8c-4f04-412a-add4-8208712646ae",
   "metadata": {},
   "source": [
    "### Trains the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dae480-ca5c-49ec-b928-1533dddf5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(dataloader, D, G, num_epochs, z_size=100):\n",
    "    samples = []\n",
    "    losses = []\n",
    "    \n",
    "    print_every = 300\n",
    "    \n",
    "    sample_size = 16\n",
    "    fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "    fixed_z = torch.from_numpy(fixed_z).float()\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        for batch_i, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images[0].size(0)\n",
    "            \n",
    "            real_images = scale(real_images)\n",
    "            \n",
    "            if train_on_gpu:\n",
    "                real_images = real_images.cuda()\n",
    "                \n",
    "            # =========================== #\n",
    "            #        Discriminator        #\n",
    "            # =========================== #\n",
    "            \n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # real image loss\n",
    "            d_out_real = D(real_images)\n",
    "            loss_real = real_loss(d_out_real)\n",
    "            \n",
    "            # generate image\n",
    "            z = np.random.uniform(-1,1, size=(batch_size, z_size))\n",
    "            z = torch.from_numpy(z).float()\n",
    "            if train_on_gpu:\n",
    "                z = z.cuda()\n",
    "            \n",
    "            # fake image loss\n",
    "            gen_im = G(z)\n",
    "            d_out_fake = D(gen_im)\n",
    "            loss_fake = fake_loss(d_out_fake)\n",
    "            \n",
    "            # backprop and step\n",
    "            d_loss = loss_fake + loss_real\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # ========================== #\n",
    "            #         Generator          #\n",
    "            # ========================== #\n",
    "            \n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            # generate image\n",
    "            z = np.random.uniform(-1,1, size=(batch_size, z_size))\n",
    "            z = torch.from_numpy(z).float()\n",
    "            if train_on_gpu:\n",
    "                z = z.cuda()\n",
    "                \n",
    "            # generate image and run thru discriminator\n",
    "            gen_im = G(z)\n",
    "            d_out_gen = D(gen_im)\n",
    "            \n",
    "            # loss, backprop, step\n",
    "            g_loss = real_loss(d_out_gen)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if batch_i % print_every == 0:\n",
    "                losses.append((d_loss.item(), g_loss.item()))\n",
    "                print('Epoch [{:4d}/{:4d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    e+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "                \n",
    "            G.eval()\n",
    "            if train_on_gpu:\n",
    "                fixed_z = fixed_z.cuda()\n",
    "            samples_z = G(fixed_z)\n",
    "            samples.append(samples_z)\n",
    "            G.train()\n",
    "    with open('samples.pkl', 'wb') as f:\n",
    "        pkl.dump(samples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789a286-55f3-4f19-9a17-72a35c42d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train(data_loader, D=D, G=G, num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
