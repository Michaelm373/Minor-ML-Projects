{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758f0e07-41e0-4190-abf8-61aaa72474b1",
   "metadata": {},
   "source": [
    "### Importing some pre-trained networks\n",
    "My computer is not powerful enough to handle the convolutional network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf0c19-5364-40ab-9dee-4b3c11d8a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "resnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "print(resnet)\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "print(vgg16)\n",
    "\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "print(resnet34)\n",
    "\n",
    "## ended up going with vgg16 because it has less layers and there are papers \n",
    "## transfering the convolutional layers from vgg16 and re-training the classification\n",
    "## layers with great success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9be063-9a03-4802-b2f8-947669a19c46",
   "metadata": {},
   "source": [
    "### Keeping the convolutional layers\n",
    "Makes the convolutional layers in the vgg16 model grad-less so backpropogating doesn't change its weights. Prints the layers in the network that require a grad to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ed878-fd90-4f26-b019-f14118122b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in vgg16.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104f1ca-eef3-470f-9385-ab1b427f4942",
   "metadata": {},
   "source": [
    "### New calssification layers\n",
    "Inserts new classification layers in the place of the original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4ae30-acfb-48e4-a562-f8cbe0864751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088, 4096)), ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(4096, 1024)), ('relu', nn.ReLU()),\n",
    "    ('fc3', nn.Linear(1024, 50)), ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "vgg16.classifier = classifier\n",
    "print(vgg16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efcfc0-258d-4101-ad62-b309afbd48ca",
   "metadata": {},
   "source": [
    "### Trains the netowrk for detecting Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bff433-e190-4690-ae3c-1365f22d020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.0001)\n",
    "epochs = 5\n",
    "\n",
    "#clears cache\n",
    "torch.cuda.empty_cache()\n",
    "#sets processing to gpu\n",
    "vgg16.cuda()\n",
    "#validation loss min for saving model\n",
    "valid_loss_min = 10000\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    #tracking loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    #sets to training mode\n",
    "    vgg16.train()\n",
    "    for images, labels in train_loader:\n",
    "        #clears optimizer and moves data to cuda\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        \n",
    "        #runs through model\n",
    "        outputs = vgg16(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #updates loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        \n",
    "        #clears cache\n",
    "        del outputs\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    else:\n",
    "        #sets to evaluation mode\n",
    "        vgg16.eval()\n",
    "        for images, labels in valid_loader:\n",
    "            #switches to gpu\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        \n",
    "            #runs the validation set\n",
    "            with torch.no_grad():\n",
    "                outputs = vgg16(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "        \n",
    "            #updates loss\n",
    "            valid_loss += loss.item()*images.size(0)\n",
    "            \n",
    "            #clears cache\n",
    "            del outputs\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    #updates overall losses\n",
    "    training_loss = train_loss/len(train_loader.dataset)\n",
    "    validation_loss = valid_loss/len(valid_loader.dataset)\n",
    "    \n",
    "    #prints progress\n",
    "    print(\"Epoch: {} \\tTraining Loss: {:.4f} \\tValidation Loss: {:.4f}\".format(\n",
    "        e+1, training_loss, validation_loss))\n",
    "    \n",
    "    #updates model\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        torch.save(vgg16.state_dict(), 'landmark_detection_vgg16.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "        print('Saving Model...')\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a662a7-732c-4223-9705-02f794e261e5",
   "metadata": {},
   "source": [
    "### Testing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df20f0c-3919-40e0-a54e-3c89ad3b9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.eval()\n",
    "vgg16.cpu()\n",
    "test_loss = 0\n",
    "for images, labels in test_loader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = vgg16(images)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()*images.size(0)\n",
    "        \n",
    "    _ , guess_tensor = torch.topk(output, 1)\n",
    "    guess = np.squeeze(guess_tensor.cpu().numpy())\n",
    "\n",
    "    testing_loss = test_loss/len(test_loader.dataset)\n",
    "    \n",
    "    images = images.cpu().numpy()\n",
    "    fig = plt.figure(figsize=(25, 5))\n",
    "    for idx in np.arange(5):\n",
    "        ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.transpose(images[idx]))\n",
    "        ax.set_title(str(classes[guess[idx]])+\"\\n\"+str(classes[labels[idx]]))\n",
    "print(f\"Testing Loss: {testing_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbfbeaf-256a-4ddd-a9be-4a5d9512c923",
   "metadata": {},
   "source": [
    "### Location finder\n",
    "Creates a library of locations and landmarks and returns the location of each landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001dbff9-0360-43b1-8a72-202ebebcb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = {'Haleakala_National_Park': 'Haleakala National Park, Hawaii', 'Mount_Rainier_National_Park':'Mount Rainier National Park, Washington', \n",
    "             'Ljubljana_Castle': 'Ljubljana Castle, Slovenia', 'Dead_Sea':'Dead Sea, Jordan Rift Valley', 'Wroclaws_Dwarves': 'Dwarves of Wroclaws, Wroclaw', \n",
    "             'London_Olympic_Stadium': 'London Olympic Stadium, London', 'Niagara_Falls': 'Niagara Falls, New York', 'Stonehenge':'Stonehenges, Salisbury Plain', \n",
    "             'Grand_Canyon': 'Grand Canyon, Arizona', 'Golden_Gate_Bridge':'Golden Gate, San Fransisco', 'Edinburgh_Castle': 'Edinburgh, Scotland', \n",
    "             'Mount_Rushmore_National_Memorial': 'Mount Rushmore, South Dakota', 'Kantanagar_Temple':'Katanagar Temple, Sri Lanka', \n",
    "             'Yellowstone_National_Park':'Yellowstone National Park, Wyoming', 'Terminal_Tower':'Cleveland, Ohio', 'Central_Park': 'Central Park, New York', \n",
    "             'Eiffel_Tower': 'Eiffel Tower, Paris', 'Changdeokgung': 'Seoul, South Korea', 'Delicate_Arch': 'Delicate Arch, Utah', 'Vienna_City_Hall': 'Vienna City Hall, Vienna', \n",
    "             'Matterhorn':'Switzerland', 'Taj_Mahal':'Taj Mahal, Agra', 'Moscow_Raceway': 'Moscow Raceway, Moscow', 'Externsteine':'Meinburg, Germany', 'Soreq_Cave': 'Bet Shemesh, Israel', \n",
    "             'Banff_National_Park':'Banff National Park, Alberta', 'Pont_du_Gard':'Pont du Gard, France', 'Seattle_Japanese_Garden':'Seattle Japanese Park, Seattle', \n",
    "             'Sydney_Harbour_Bridge':'Sydney Harbour Bridge, Sydney', 'Petronas_Towers':'Kuala Lampur, Malaysia', 'Brooklyn_Bridge':'Brooklyn, New York', \n",
    "             'Washington_Monument': 'Washington Monument, Washington', 'Hanging_Temple':'Hanging Temple, China', 'Sydney_Opera_House': 'Sydney Australia', \n",
    "             'Great_Barrier_Reef':'Great Barrier Reef, Australia', 'Monumento_a_la_Revolucion':'Plaza de la Republica, Mexico City', 'Badlands_National_Park':'Badlands National Park, South Dakota', \n",
    "             'Atomium':'Atomium, Belgium', 'Forth_Bridge': 'Forth Bridge, Firth of Forth', 'Gateway_of_India':'Gateway of India, Mumbai', 'Stockholm_City_Hall':'Stockholm, Sweden', \n",
    "             'Machu_Picchu':'Machu Pichu, Peru', 'Death_Valley_National_Park':'Death Valley, California', 'Gullfoss_Falls':'Gullfoss Falls, Iceland', \n",
    "             'Trevi_Fountain':'Trevi Fountain, Rome', 'Temple_of_Heaven':'Temple of Heaven, Dongcheng', 'Great_Wall_of_China':'Great Wall of China, China', \n",
    "             'Prague_Astronomical_Clock':'Prague, Chezch Republic', 'Whitby_Abbey':'Whitby Abbey, Yorkshire', 'Temple_of_Olympian_Zeus': 'Temple of Olympian Zeus, Athens'}\n",
    "\n",
    "def location_finder(x):\n",
    "    return locations[classes[x]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4db9b2-1a5d-441e-95d7-49c2eba91d9a",
   "metadata": {},
   "source": [
    "### Impliments the location finder on a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa330ae0-9034-44c1-ade2-0c581eccbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(valid_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "with torch.no_grad():\n",
    "        output = vgg16(images)\n",
    "        \n",
    "_ , guess_tensor = torch.topk(output, 1)\n",
    "guess = np.squeeze(guess_tensor.cpu().numpy())\n",
    "location_finder(guess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
